{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuHhQG7ZT/eJ/DU38AYRm2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zHazyl/ml-from-scratch/blob/main/langchain-course/practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ugOTjbFsspLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-hub"
      ],
      "metadata": {
        "id": "id6hxQXV1wI6",
        "outputId": "34d8f417-51d8-42db-a5db-3b0df2ca46e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import google.generativeai as genai\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import MessagesPlaceholder, HumanMessagePromptTemplate, ChatPromptTemplate, PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory, FileChatMessageHistory, ConversationSummaryMemory\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "chat = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    client=genai,\n",
        "    temperature=0.3,\n",
        "    # convert_system_message_to_human=True\n",
        ")\n",
        "\n",
        "# chat = HuggingFaceHub(repo_id=\"abacusai/Liberated-Qwen1.5-72B\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
        "\n",
        "chat = ChatOpenAI()\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    chat_memory=FileChatMessageHistory(\"messages.json\"),\n",
        "    memory_key=\"messages\",\n",
        "    return_messages=True)\n",
        "\n",
        "# memory = ConversationSummaryMemory(\n",
        "#     # chat_memory=FileChatMessageHistory(\"messages.json\"),\n",
        "#     memory_key=\"messages\",\n",
        "#     return_messages=True,\n",
        "#     llm=chat\n",
        "# )\n",
        "\n",
        "prompt = ChatPromptTemplate(\n",
        "    input_variables=[\"content\"],\n",
        "    messages=[\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# memory_prompt_template = \"\"\"<|im_start|>system\n",
        "# You are Liberated, a helpful AI assistant.<|im_end|>\n",
        "# <|im_start|>user\n",
        "# {content}<|im_end|>\n",
        "# \"\"\"\n",
        "\n",
        "# def create_prompt_from_template(template):\n",
        "#     return PromptTemplate.from_template(template)\n",
        "\n",
        "# prompt = create_prompt_from_template(memory_prompt_template)\n",
        "\n",
        "\n",
        "chain = LLMChain(\n",
        "    llm=chat,\n",
        "    prompt=prompt,\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "while True:\n",
        "\n",
        "    content = input(\">> \")\n",
        "\n",
        "    result = chain({\"content\": content})\n",
        "\n",
        "    print(result['text'])\n"
      ],
      "metadata": {
        "id": "wesswBwesySG",
        "outputId": "d4b96f98-2ad0-448d-a116-1543ec8f3764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> What is 1 + 1?\n",
            "1 + 1 is 2.\n",
            ">> And three 3?\n",
            "1 + 1 is 2, and 2 + 3 is 5.\n",
            ">> You got it!\n",
            "I'm glad I could help! Is there anything else I can assist you with today?\n",
            ">> Explain what is the Hugging face\n",
            "Hugging Face is a company that provides a platform for sharing and collaborating on machine learning models. It offers a variety of tools and resources for developers and researchers to build, train, and deploy machine learning models.\n",
            "\n",
            "Hugging Face's platform includes a model hub, where users can share and discover machine learning models. The model hub contains a wide range of models, including models for natural language processing, computer vision, and speech recognition.\n",
            "\n",
            "Hugging Face also provides a set of tools for training and deploying machine learning models. These tools include:\n",
            "\n",
            "* **Transformers:** A library for training and deploying transformer-based models.\n",
            "* **Datasets:** A collection of datasets for training machine learning models.\n",
            "* **Spaces:** A platform for deploying and managing machine learning models.\n",
            "\n",
            "Hugging Face's platform is used by a wide range of organizations, including Google, Facebook, and Microsoft. It is also used by researchers and developers around the world to build and deploy machine learning models.\n",
            "\n",
            "Here are some of the benefits of using Hugging Face:\n",
            "\n",
            "* **Access to a wide range of machine learning models:** Hugging Face's model hub contains a wide range of machine learning models, which can be used for a variety of tasks.\n",
            "* **Tools for training and deploying machine learning models:** Hugging Face provides a set of tools for training and deploying machine learning models, which makes it easy to get started with machine learning.\n",
            "* **Community support:** Hugging Face has a large and active community of users, who can provide support and advice.\n",
            "\n",
            "Overall, Hugging Face is a valuable resource for developers and researchers who are working with machine learning. It provides a platform for sharing and collaborating on machine learning models, as well as a set of tools for training and deploying machine learning models.\n",
            ">> Wow what do u mean?\n",
            "Hugging Face is a company that provides a platform for sharing and collaborating on machine learning models. It offers a variety of tools and resources for developers and researchers to build, train, and deploy machine learning models.\n",
            "\n",
            "Hugging Face's platform includes a model hub, where users can share and discover machine learning models. The model hub contains a wide range of models, including models for natural language processing, computer vision, and speech recognition.\n",
            "\n",
            "Hugging Face also provides a set of tools for training and deploying machine learning models. These tools include:\n",
            "\n",
            "* **Transformers:** A library for training and deploying transformer-based models.\n",
            "* **Datasets:** A collection of datasets for training machine learning models.\n",
            "* **Spaces:** A platform for deploying and managing machine learning models.\n",
            "\n",
            "Hugging Face's platform is used by a wide range of organizations, including Google, Facebook, and Microsoft. It is also used by researchers and developers around the world to build and deploy machine learning models.\n",
            "\n",
            "Here are some of the benefits of using Hugging Face:\n",
            "\n",
            "* **Access to a wide range of machine learning models:** Hugging Face's model hub contains a wide range of machine learning models, which can be used for a variety of tasks.\n",
            "* **Tools for training and deploying machine learning models:** Hugging Face provides a set of tools for training and deploying machine learning models, which makes it easy to get started with machine learning.\n",
            "* **Community support:** Hugging Face has a large and active community of users, who can provide support and advice.\n",
            "\n",
            "Overall, Hugging Face is a valuable resource for developers and researchers who are working with machine learning. It provides a platform for sharing and collaborating on machine learning models, as well as a set of tools for training and deploying machine learning models.\n",
            "\n",
            "To answer your question, \"Wow what do u mean?\", I am providing a more detailed explanation of what Hugging Face is and how it can be used. I hope this helps!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-76a5b30d292d>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p-njsAW4tiwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}